---
title: "Data Wrangling & EDA"
output: html_notebook
---
```{r libraries, warning=FALSE, include= FALSE}
#load needed libraries
library(tidyverse)
library(lubridate)
library(gridExtra) # test
```
```{r set_wd_load_data, warning=FALSE, include=FALSE, message=FALSE}
#Setting wd and loading data
#put the path of where you are storing the data on your computer
paths = c('C:/Users/eliza/Documents/BANA 7047 - Data Mining II/Group Project/Data', 'C:/Users/ashle/Downloads/8451_The_Complete_Journey_2_Master (1)/The_Complete_Journey_2_Master', 'path3')
#use the code Sys.info()[7] to find out how your name is stored on your local machine, copy to this list
names(paths) = c('eliza', 'ashle', 'name3')
#this will set the wd
setwd(paths[Sys.info()[7]])

#load data sets
households <- read_csv('5000_households.csv', col_types = cols(.default = 'f', HSHD_NUM = 'c'), na = c("null", "", "NA", "NOT AVAILABLE", "Unknown"))
transactions <- read_csv('5000_transactions.csv', col_types = cols(.default = '?', STORE_R = 'f', YEAR = 'f'), na = c("null", "", "NA"))
products <- read_csv('5000_products.csv', col_types = cols(.default = 'f', PRODUCT_NUM = 'c'), na = c("null", "", "NA"))

#rename column 'X5' to be more descriptive
products <- products %>% rename(ORGANIC = X5)

#rename truncated date and store region column on transactions
transactions <- transactions %>%
  rename(DATE = PURCHASE_) %>%
  rename(REGION = STORE_R)

#make 'DATE' column in transactions dataset into a date format
transactions <- transactions %>%
  mutate(DATE = dmy(DATE))

#reorder factors on households dataset
households <- households %>%
  mutate(AGE_RANGE = fct_relevel(AGE_RANGE,
                                  "19-24",
                                  "25-34",
                                  "35-44",
                                  "45-54",
                                  "55-64",
                                  "65-74",
                                  "75+")) %>%
  mutate(INCOME_RANGE = fct_relevel(INCOME_RANGE,
                                    "UNDER 35K",
                                    "35-49K",
                                    "50-74K",
                                    "75-99K",
                                    "100-150K",
                                    "150K+")) %>%
  mutate(HH_SIZE = fct_relevel(HH_SIZE,
                               "1",
                               "2",
                               "3",
                               "4",
                               "5+")) %>%
  mutate(CHILDREN = fct_relevel(CHILDREN,
                                "1",
                                "2",
                                "3"))

#By default the households dataset encodes all households without children as having a 'CHILDREN' value of NA. This encodes these households with a CHILDREN value of 0 to avoid missing values.
households <- households %>%
  mutate(CHILDREN = ifelse(HSHD_COMPOSITION %in% c("1 Adult", "2 Adults", "Single Male", "Single Female"), 0, CHILDREN))

#There are some transactions with negative spends and negative units or units of 0, assuming that the negative spends and negative units are returns, unsure of the transactions with 0 units, but we are filtering these from the transactions table
returns <- transactions %>% 
  filter(UNITS < 1) #I am assuming the items with negative spends and positive units are items bought with a coupon that reduced the price below 0

transactions <- anti_join(transactions, returns, by = c("BASKET_NUM", "PRODUCT_NUM"))
```
```{r hh_plots, include=FALSE}
#Since we are only working with complete cases for prediction, I re-did these graphs to show only complete cases

income <- households %>%
  filter(complete.cases(.) == TRUE) %>%
  mutate(INCOME_RANGE = fct_recode(INCOME_RANGE, "<35K" = "UNDER 35K")) %>%
  ggplot() +
    geom_bar(mapping = aes(x = INCOME_RANGE)) +
    labs(x = "", y = "", title = "Household Income")

age <- households %>%
  filter(complete.cases(.) == TRUE) %>%
  ggplot() +
    geom_bar(mapping = aes(x = AGE_RANGE)) +
    labs(x = "", y = "", title = "Primary Shopper Age")

size <- households %>%
  filter(complete.cases(.) == TRUE) %>%
  ggplot() +
    geom_bar(mapping = aes(x = HH_SIZE)) +
    labs(x = "", y = "", title = "Size of Household")

comp <- households %>%
  filter(complete.cases(.) == TRUE) %>%
  ggplot() +
    geom_bar(mapping = aes(x = HSHD_COMPOSITION)) +
    labs(x = "", y = "", title = "Household Composition")

children <- households %>%
  filter(complete.cases(.) == TRUE) %>%
  ggplot() +
    geom_bar(mapping = aes(x = CHILDREN)) +
    labs(x = "", y = "", title = "Number of Children")

homeowner <- households %>%
  filter(complete.cases(.) == TRUE) %>%
  ggplot() +
    geom_bar(mapping = aes(x = HOMEOWNER)) +
    labs(x = "", y = "", title = "Homeowner Status") +
    coord_flip()

loyalty <- households %>%
  filter(complete.cases(.) == TRUE) %>%
  ggplot() +
    geom_bar(mapping = aes(x = L)) +
    labs(x = "", y = "", title = "Loyalty Card Status") +
    coord_flip()

marital <- households %>%
  filter(complete.cases(.) == TRUE) %>%
  ggplot() +
    geom_bar(mapping = aes(x = MARITAL)) +
    labs(x = "", y = "", title = "Marital Status") +
    coord_flip()
```
# Background Information and Objective

Understanding what drives customers to buy organic products is key as in many segments the market growth of organic products is outstripping that of the overall segment. Organic products also represent billions of dollars in sales and the availability of orgnic products is a key factor in why some consumers pick one grocery store over another.

A recent report from the Organic Trade Association stated that the U.S. market for organic products was \$52.2 billion and accounted for 5.7% of all food sales in the United States in 2018. They reported that the majority of organic food sales were fruits and vegetables, accounting for $17.4 billion in sales; dairy and eggs made up the second-largest organic food category at \$6.5 billion in sales. Sales of organic fruits and vegetables grew by 5.6% which far surpassed the growth of the overall fruit and vegetable market at 1.7%. Non-food organic products saw 10.6% overall growth from 2017 to 2018 also surpassing the growth of the overall non-food segment at 3.6% (Redman). And recent polling by IRI, a consumer research company, found that 49% of Millennials and 40% of Gen X shoppers consider having a good selection of natural and organic foods important in selecting a grocery store (Emarketer). 

For this project, we are acting as a team of analysts that is interested in identifying households and baskets that are likely to buy organic products so we know who to target for an organic product marketing campaign. In order to do this, we will use data at both the household and basket level and try classification models to accurately identify these households. We are also interested in organic trends over time and will use a classification model to attempt to flag households who have increased their spending on organic products in year two.

(Citations
Redman, Russell. "Organic Products Hit a Record-Breaking High." Supermarket News (May 20, 2019). https://search-proquest-com.proxy.libraries.uc.edu/docview/2238503079?accountid=2909.)

Emarketer - Data is from the January 2020 IRI report titled "Consumer Connect Q4 2019: Channel Trends in CPG Today." 2,366 US internet users ages 18+ were surveyed online during December 2019.
https://chart-na1.emarketer.com/234160/attributes-us-internet-users-find-important-store-selection-process-by-generation-dec-2019-of-respondents-each-group

# The Data

The data set we are using for our project is called "The Complete Journey 2.0" and it is found on the 84.51 website. This data set has transactions at the household level from a group of 5,000 households over a two year period. This is a relational data set comprised of household data, transaction data, and product data that can be combined by household and product IDs. The household data has demographic information such as the size, income, and age of the household. The transaction data contains information like the amount of money spent and the number of items in a transaction. The product data contains information like the product category, whether a product is organic, and whether the product is a private or national brand. 

## Household Data Set

The households data set has 5000 observations, one for each household with a unique key for each household and 8 variables which give demographic data. The column 'HSHD_NUM' is a unique key that links this data set to the transactions data set. Demographic variables include age range, marital status, income range, number of children, household composition, household size, homeowner status, and whether the household has a store loyality card. Every household has a 'HSHD_NUM' key and information on if that household has a loyality card. Complete demographic data is available for  `r sum(complete.cases(households))` and partial demographic data is available for `r sum(rowSums(is.na(households[3:9]))<7 & rowSums(is.na(households[3:9]))>0)` households.

The majority of households fall between the ages of 35 and 74 and the distribution of age appears to be fairly normal with the exception of the very low number of households in the 19-24 range. This could be due to the fact that many younger shoppers still use their parent's loyalty card, so their data could show up under their parent's age. The vast majority of households are owners as opposed to renters and the majority of households also have a loyalty card. Income is slightly skewed right with fewer households making above $75,000. Many households in the data set are also comprised of only two adults, or two adults with one child. 

```{r hh_grid_plots, echo=FALSE, fig.height=10, fig.width=8}
grid.arrange(size, age, income, homeowner, marital, children, ncol = 2)
```
```{r hh_loyalty_plot, echo=FALSE, fig.height=3, fig.width=5}
loyalty
```
```{r hh_comp_plot, echo=FALSE, fig.height=4, fig.width=8}
comp
```
## Products Data Set
The products data set has 151,141 observations and 5 variables which give information about the product. Each product has a unique 'PRODUCT_NUM' that links it to the transaction data set. Information such as the product department (food, non-food, or pharmacy), whether the product is a private or national brand, whether the product is organic, and the commodity of the product can be found in this data set. Product commidity is the most detailed information given about a given product so while we cannot pinpoint specific brands in this data set, we can see which categories of products are being bought organic. 

## Transactions Data Set
The transactions data set has 10,625,553 observations and 9 variables which give detailed information about every transaction over a two year period. Both the households and products data sets can be linked to the transaction set by the 'HSHD_NUM' and 'PRODUCT_NUM' keys. Information such as the date of purchase, the amount spent and number of units purchased, and store region can be found in this data set. 

Through data exploration, we found that 6,427 transactions had negative spend. We are assuming that these records account for returns, so we chose to filter them out of the data set for the rest of our analysis. The transaction data set now contains 10,619,064 records. 

# Feature Engineering

## Household Purchasing of Organic Products

## Market Basket

```{r}
#to use later
#res <- lapply( mydf , function(x) rbind( mean = mean(x) ,
 #                                 sd = sd(x) ,
  #                                median = median(x) ,
   #                               minimum = min(x) ,
    #                              maximum = max(x) ,
     #                             s.size = length(x) ) )
```


```{r baskets, include=FALSE}
#creating a data set with basket level detail - filter out returns
baskets <- transactions %>%
  group_by(HSHD_NUM, BASKET_NUM) %>%
  summarise(
    PRODUCTS = n(),
    TOTAL_SPEND = sum(SPEND),
    TOTAL_UNITS = sum(UNITS)
  )

summary(baskets)
```
```{r key_check, include=FALSE}
#confirming primary keys in each table are unique
households %>% 
  count(HSHD_NUM) %>% 
  filter(n > 1)

products %>%
  count(PRODUCT_NUM) %>% 
  filter(n > 1)

baskets %>%
  count(BASKET_NUM) %>% 
  filter(n > 1)
```
```{r market_basket, include=FALSE}
market_basket <- products %>%
  mutate(ORGANIC = str_replace(ORGANIC, "N", "NON-ORGANIC")) %>%
  mutate(ORGANIC = str_replace(ORGANIC, "Y", "ORGANIC")) %>% 
  mutate(PRODUCT_NAME = str_c(ORGANIC, COMMODITY, sep = " ")) %>%
  select(PRODUCT_NUM, PRODUCT_NAME) %>%
  mutate(INDICATOR = 1) %>%
  right_join(transactions, by = "PRODUCT_NUM") %>%
  select(BASKET_NUM, PRODUCT_NAME, INDICATOR) %>%
  distinct() %>%
  pivot_wider(names_from = PRODUCT_NAME, 
              values_from = INDICATOR, 
              values_fill = list(INDICATOR = 0))

```
```{r organic_households, include=FALSE}
organic_households <- products %>%
  select(PRODUCT_NUM, ORGANIC) %>%
  mutate(ORGANIC = str_replace(ORGANIC, "N", "NORG")) %>%
  mutate(ORGANIC = str_replace(ORGANIC, "Y", "ORG")) %>% 
  right_join(transactions, by = "PRODUCT_NUM") %>%
  group_by(HSHD_NUM, ORGANIC) %>%
  summarise(
    TOTAL_SPEND = sum(SPEND),
    TOTAL_UNITS = sum(UNITS),
    UNIQUE_ITEMS = n_distinct(PRODUCT_NUM)) %>% 
  ungroup() %>%
  pivot_wider(names_from = ORGANIC, values_from = c(TOTAL_SPEND, TOTAL_UNITS, UNIQUE_ITEMS), values_fill = list(TOTAL_SPEND = 0, TOTAL_UNITS = 0, UNIQUE_ITEMS = 0)) %>%
  left_join(households, by = "HSHD_NUM") %>%
  mutate(ORG_HOUSE = ifelse(TOTAL_UNITS_ORG > 0, 1, 0)) %>%
  filter(complete.cases(.) == TRUE)
```
```{r}
#save out created datasets to work with in future

setwd(paths[Sys.info()[7]])
save(market_basket, file = "market_basket.Rdata", compress = FALSE)
save(organic_households, file = "organic_households.Rdata", compress = FALSE)

#should be able to use function "load(file = "organic_households.Rdata")" to load dataset when you need it in a different notebook
```

```{r}
summary(organic_households)
```

## Proposed Work for the Rest of the Project


## Daily SPEND Prediction 
```{r}
# merge data by "HSHD_NUM" and "PRODUCT_NUM"
merge_df <- merge(transactions,products,by="PRODUCT_NUM")
merge_df <- merge(merge_df,households,by="HSHD_NUM")
str(merge_df)
```
```{r}
# set HSHD_NUM/PRODUCT_NUM /BASKET_NUM to interger variable
merge_df[sapply(merge_df, is.character)] <- lapply(merge_df[sapply(merge_df, is.character)],as.integer)
```

```{r}
# filter Organic transactions and split by YEAR
organic <- merge_df%>%filter(ORGANIC=="Y")
organic_2016 <- organic%>%filter(YEAR=="2016")
organic_2017 <- organic%>%filter(YEAR=="2017")

# check "organic_2016" structure
str(organic_2016)
```
```{r}
# check range of "organic_2016$WEEK_NUM"
summary(organic_2016$WEEK_NUM)
```
```{r}
# set "organic_2016$WEEK_NUM" as factor
organic_2016$WEEK_NUM <- as.factor(organic_2016$WEEK_NUM)
```

```{r}
# check range of "organic_2017$WEEK_NUM"
summary(organic_2017$WEEK_NUM)
```


```{r}
# set "organic_2017$WEEK_NUM" as factor
organic_2017$WEEK_NUM <- as.factor(organic_2017$WEEK_NUM)

# reset organic_2017$WEEK_NUM level as 1:52
levels(organic_2017$WEEK_NUM) <- seq(1,52,1)
levels(organic_2017$WEEK_NUM)
```

```{r}
# aggregate data by "WEEK_NUM"
organic_SPEND_week_2016 <- organic_2016%>%group_by(WEEK_NUM)%>%
  summarise(SPEND_SUM_16=sum(SPEND),          # total spend(can be view as total revenue) for each week
            SPEND_AVG_16=mean(SPEND),        # average spend(can be view as average revenue) for each week
            TRAN_NUM_16=n())%>%
  mutate(WEEK_NUM=as.integer(WEEK_NUM))

organic_SPEND_week_2017 <- organic_2017%>%group_by(WEEK_NUM)%>%
  summarise(SPEND_SUM_17=sum(SPEND),          # total spend(can be view as total revenue) for each week
            SPEND_AVG_17=mean(SPEND),        # average spend(can be view as average revenue) for each week
            TRAN_NUM_17=n())%>%
  mutate(WEEK_NUM=as.integer(WEEK_NUM))

organic_SPEND_week_2016
organic_SPEND_week_2017
```
```{r}
# bar chart Weekly Agregate SPEND each year
library(ggplot2)
ggplot(organic_SPEND_week_2016,aes(WEEK_NUM,SPEND_SUM_16))+geom_bar(stat = "identity")+
  ggtitle("Organic Weekly Agregate SPEND - 2016")

ggplot(organic_SPEND_week_2017,aes(WEEK_NUM,SPEND_SUM_17))+geom_bar(stat = "identity")+
  ggtitle("Organic Weekly Agregate SPEND - 2017")
```
```{r}
# combine Weekly Agregate SPEND in a data set
organic_SPEND_week <- merge(organic_SPEND_week_2016,organic_SPEND_week_2017,by="WEEK_NUM")
organic_SPEND_week
```
```{r}
# Organic Weekly Agregate SPEND_SUM
ggplot(organic_SPEND_week, aes(WEEK_NUM)) + 
  geom_line(aes(y = SPEND_SUM_16, colour = "SPEND_SUM_16")) + 
  geom_line(aes(y = SPEND_SUM_17, colour = "SPEND_SUM_17"))+
  theme(legend.position="bottom")+
  ggtitle("Organic Weekly Agregate SPEND_SUM")
```
```{r}
# Organic Weekly Agregate SPEND_AVG
ggplot(organic_SPEND_week, aes(WEEK_NUM)) + 
  geom_line(aes(y = SPEND_AVG_16, colour = "SPEND_AVG_16")) + 
  geom_line(aes(y = SPEND_AVG_17, colour = "SPEND_AVG_17"))+
  theme(legend.position="bottom")+
  ggtitle("Organic Weekly Agregate SPEND_AVG")
```
```{r}
# aggregate data by "DATE"
organic_SPEND_DATE <- organic%>%group_by(DATE)%>%
  summarise(SPEND_SUM=sum(SPEND),          # daily total spend(can be view as total revenue)
            SPEND_AVG=mean(SPEND),        # daily average spend(can be view as average revenue)
            TRAN_NUM=n())
  
organic_SPEND_DATE
```
```{r}
# plot daily spend 

library(latticeExtra)

# --> construct separate plots for each series
obj1 <- xyplot(SPEND_SUM ~ DATE, organic_SPEND_DATE, type = "l" , lwd=2)
obj2 <- xyplot(SPEND_AVG ~ DATE, organic_SPEND_DATE, type = "l", lwd=2)
 
# --> Make the plot with second y axis AND legend:
doubleYScale(obj1, obj2, text = c("SPEND_SUM_daily", "SPEND_AVG_daily") , add.ylab2 = TRUE)
```
# Idea from the SPEND Time Series Plots
* From the Weekly SPEND Plots, we can see weekly Organic_SPEND_SUM increases in 2017 in general. However, Organic_SPEND_AVG in 2017 seems decreases in general.

* We are curious about which elements drove the Organic_SPEND_SUM up in 2017 and curious about predicting future Organic Products revenue.
  - To fit Linear Regression to training data. Use Stepwise and LASSO approach to do variable selection.
  - To fit Random Forest, Boosting, GAM models into trainning data.
  - Compare models and select the best model for predicting Organic Products Revenue and for identifing important varibles which can impact organic revenue significantly.
  
* We are also curious about which segmentation we should focus on.
  - We are going to fit KNN, Clustering Methods, Logistic Regression, Random Forest, Boosting, GAM, NN into training date.
  - Compare and selecte best model for identifying important customers for organic products selling.


