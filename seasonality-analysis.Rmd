---
title: "Seasonality"
output:
  html_document:
    df_print: paged
  html_notebook: default
  word_document: default
---
```{r libraries, warning=FALSE, include= FALSE}
#load needed libraries
library(tidyverse)
library(lubridate)
library(gridExtra) 
library(modeest)
library(knitr)
library(kableExtra)
library(latticeExtra)
```
```{r set_wd_load_data, include=FALSE, warning=FALSE, message=FALSE}
#Setting wd and loading data
#put the path of where you are storing the data on your computer
paths = c('C:/Users/eliza/Documents/BANA 7047 - Data Mining II/Group Project/Data', 'C:/Users/ashle/Downloads/8451_The_Complete_Journey_2_Master (1)/The_Complete_Journey_2_Master', 'C:/Users/xiaoj/Desktop/BANA/BANA7047 Data Mining II/Project/8451_The_Complete_Journey_2_Master/The_Complete_Journey_2_Master')
#use the code Sys.info()[7] to find out how your name is stored on your local machine, copy to this list
names(paths) = c('eliza', 'ashle', 'xiaoj')
#this will set the wd
setwd(paths[Sys.info()[7]])

#load data sets
households <- read_csv('5000_households.csv', col_types = cols(.default = 'f', HSHD_NUM = 'c'), na = c("null", "", "NA", "NOT AVAILABLE", "Unknown"))
transactions <- read_csv('5000_transactions.csv', col_types = cols(.default = '?', STORE_R = 'f', YEAR = 'f'), na = c("null", "", "NA"))
products <- read_csv('5000_products.csv', col_types = cols(.default = 'f', PRODUCT_NUM = 'c'), na = c("null", "", "NA"))

#rename column 'X5' to be more descriptive
products <- products %>% rename(ORGANIC = X5)

#rename truncated date and store region column on transactions
transactions <- transactions %>%
  rename(DATE = PURCHASE_) %>%
  rename(REGION = STORE_R)

#make 'DATE' column in transactions dataset into a date format
transactions <- transactions %>%
  mutate(DATE = dmy(DATE))

#reorder factors on households dataset
households <- households %>%
  mutate(AGE_RANGE = fct_relevel(AGE_RANGE,
                                  "19-24",
                                  "25-34",
                                  "35-44",
                                  "45-54",
                                  "55-64",
                                  "65-74",
                                  "75+")) %>%
  mutate(INCOME_RANGE = fct_relevel(INCOME_RANGE,
                                    "UNDER 35K",
                                    "35-49K",
                                    "50-74K",
                                    "75-99K",
                                    "100-150K",
                                    "150K+")) %>%
  mutate(HH_SIZE = fct_relevel(HH_SIZE,
                               "1",
                               "2",
                               "3",
                               "4",
                               "5+")) %>%
  mutate(CHILDREN = fct_relevel(CHILDREN,
                                "1",
                                "2",
                                "3"))

#By default the households dataset encodes all households without children as having a 'CHILDREN' value of NA. This encodes these households with a CHILDREN value of 0 to avoid missing values.
households <- households %>%
  mutate(CHILDREN = ifelse(HSHD_COMPOSITION %in% c("1 Adult", "2 Adults", "Single Male", "Single Female"), 0, CHILDREN))

#There are some transactions with negative spends and negative units or units of 0, assuming that the negative spends and negative units are returns, unsure of the transactions with 0 units, but we are filtering these from the transactions table
returns <- transactions %>% 
  filter(UNITS < 1) #I am assuming the items with negative spends and positive units are items bought with a coupon that reduced the price below 0

transactions <- anti_join(transactions, returns, by = c("BASKET_NUM", "PRODUCT_NUM"))
```

## Organic Selling Seasonality Analysis

* Seasonality is common influnce factor in marketing. We are interested in detecting When/Where/How to conduct better organic marketing strategy. To that end, we use weekly organic "SPEND" data to detect possible seasonality patterns.
* From organic "SPEND" time series plots, we can sense some seasonality.
* In order to find out more accurate seasonality insights, we fit PAC/K-means/Hierarchical Clustering models into our weekly organic "SPEND" time series data to help us detect more accurate seasonality patterns and forecast future trend.


```{r org_merge, include=FALSE}
# merge data by "HSHD_NUM" and "PRODUCT_NUM"
merge_df <- merge(transactions,products,by="PRODUCT_NUM")
merge_df <- merge(merge_df,households,by="HSHD_NUM")
str(merge_df)
```
```{r org_int,include=FALSE}
# set HSHD_NUM/PRODUCT_NUM /BASKET_NUM to interger variable
merge_df[sapply(merge_df, is.character)] <- lapply(merge_df[sapply(merge_df, is.character)],as.integer)
head(merge_df)
```

```{r yr_split,include=FALSE}
# filter Organic transactions and split by YEAR
organic <- merge_df%>%filter(ORGANIC=="Y")%>%mutate(WEEK_NUM=as.integer(WEEK_NUM),
                                                    HSHD_NUM=as.factor(HSHD_NUM),
                                                    PRODUCT_NUM=as.factor(PRODUCT_NUM),
                                                    BASKET_NUM=as.factor(BASKET_NUM))
organic_2016 <- organic%>%filter(YEAR=="2016")
organic_2017 <- organic%>%filter(YEAR=="2017")
summary(organic)
# check "organic_2016" structure
str(organic_2016)
```
```{r str2016,include=FALSE}
# check range of "organic_2016$WEEK_NUM"
summary(organic_2016$WEEK_NUM)
```
```{r fac2016week,include=FALSE}
# set "organic_2016$WEEK_NUM" as factor
organic_2016$WEEK_NUM <- as.factor(organic_2016$WEEK_NUM)
```
```{r week2017,include=FALSE}
# check range of "organic_2017$WEEK_NUM"
summary(organic_2017$WEEK_NUM)
```
```{r fac_week_2017,include=FALSE}
# set "organic_2017$WEEK_NUM" as factor
organic_2017$WEEK_NUM <- as.factor(organic_2017$WEEK_NUM)

# reset organic_2017$WEEK_NUM level as 1:52
levels(organic_2017$WEEK_NUM) <- seq(1,52,1)
levels(organic_2017$WEEK_NUM)
```
```{r rbind_org, include=FALSE}
# concatenate data
organic_week <- rbind(organic_2016,organic_2017)
summary(organic_week)
```
```{r org_week_spend_region,include=FALSE}
# aggregate SPEND by week & region
org_week_east_spend <- organic%>%filter(REGION=="EAST")%>%group_by(WEEK_NUM)%>%summarise(SPEND_E=sum(SPEND))
org_week_south_spend <- organic%>%filter(REGION=="SOUTH")%>%group_by(WEEK_NUM)%>%summarise(SPEND_S=sum(SPEND))
org_week_west_spend <- organic%>%filter(REGION=="WEST")%>%group_by(WEEK_NUM)%>%summarise(SPEND_W=sum(SPEND))
org_week_central_spend <- organic%>%filter(REGION=="CENTRAL")%>%group_by(WEEK_NUM)%>%summarise(SPEND_C=sum(SPEND))
organic_week_reg_spend <- merge(org_week_east_spend,org_week_south_spend,by="WEEK_NUM")
organic_week_reg_spend <- merge(organic_week_reg_spend,org_week_west_spend,by="WEEK_NUM")
organic_week_reg_spend <- merge(organic_week_reg_spend,org_week_central_spend,by="WEEK_NUM")
organic_week_reg_spend
```
```{r week_reg_org_spend, echo=FALSE}
# plot Organic Weekly Agregate SPEND by REGION
ggplot(organic_week_reg_spend, aes(WEEK_NUM)) + 
  geom_line(aes(y = SPEND_E, colour = "EAST")) + 
  geom_line(aes(y = SPEND_S, colour = "SOUTH"))+
  geom_line(aes(y = SPEND_W, colour = "WEST"))+
  geom_line(aes(y = SPEND_C, colour = "CENTRAL"))+
  theme(legend.position="bottom")+
  ggtitle("Organic Weekly Agregate SPEND by REGION")+
  ylab("Weekly Aggregated SPEND")
```
```{r organic_week_dep_spend, include=FALSE}
# aggregate SPEND by week & DEPARTMENT
org_week_nfood_spend <- organic%>%filter(DEPARTMENT=="NON-FOOD")%>%group_by(WEEK_NUM)%>%summarise(SPEND_NFOOD=sum(SPEND))
org_week_food_spend <- organic%>%filter(DEPARTMENT=="FOOD")%>%group_by(WEEK_NUM)%>%summarise(SPEND_FOOD=sum(SPEND))
org_week_phar_spend <- organic%>%filter(DEPARTMENT=="PHARMA")%>%group_by(WEEK_NUM)%>%summarise(SPEND_PHAR=sum(SPEND))
org_week_phar_spend # PHARMA data is omited due to very limited records
organic_week_dep_spend <- merge(org_week_nfood_spend,org_week_food_spend,by="WEEK_NUM")
#organic_week_dep_spend <- merge(organic_week_dep_spend,org_week_phar_spend,by="WEEK_NUM")
#organic_week_dep_spend <- organic_week_dep_spend%>%arrange(WEEK_NUM)

organic_week_dep_spend
```
```{r plot_organic_week_dep_spend,echo=FALSE}
# plot Organic Weekly Agregate SPEND by DEPARTMENT
# --> construct separate plots for each series
obj1 <- xyplot(SPEND_NFOOD ~ WEEK_NUM, organic_week_dep_spend, main="Organic Weekly Agregate SPEND by DEPARTMENT",type = "l" , lwd=2)
obj2 <- xyplot(SPEND_FOOD ~ WEEK_NUM, organic_week_dep_spend, type = "l", lwd=2)
# --> Make the plot with second y axis AND legend:
doubleYScale(obj1, obj2, text = c("NON-FOOD", "FOOD") , add.ylab2 = TRUE)
```
```{r organic_week_brand_spend,include=FALSE}
# aggregate SPEND by week & BRAND_TY
org_week_pri_spend <- organic%>%filter(BRAND_TY=="PRIVATE" )%>%group_by(WEEK_NUM)%>%summarise(SPEND_PRI=sum(SPEND))
org_week_nat_spend <- organic%>%filter(BRAND_TY=="NATIONAL")%>%group_by(WEEK_NUM)%>%summarise(SPEND_NAT=sum(SPEND))
organic_week_brand_spend <- merge(org_week_pri_spend,org_week_nat_spend,by="WEEK_NUM")
organic_week_brand_spend
```
```{r plot_organic_week_brand_spend,echo=FALSE}
# plot Organic Weekly Agregate SPEND by BRAND_TY
ggplot(organic_week_brand_spend, aes(WEEK_NUM)) + 
  geom_line(aes(y = SPEND_PRI, colour = "PRIVATE")) + 
  geom_line(aes(y = SPEND_NAT, colour = "NATIONAL")) +  
  theme(legend.position="bottom")+
  ggtitle("Organic Weekly Agregate SPEND by BRAND_TY")+
  ylab("Weekly Aggregated SPEND")
```
```{r organic_week_loy_spend,include=FALSE}
# aggregate SPEND by week & Loyaty
org_week_loy_spend <- organic%>%filter(L=="Y" )%>%group_by(WEEK_NUM)%>%summarise(SPEND_LOY=sum(SPEND))
org_week_nloy_spend <- organic%>%filter(L=="N")%>%group_by(WEEK_NUM)%>%summarise(SPEND_NLOY=sum(SPEND))
organic_week_loy_spend <- merge(org_week_loy_spend,org_week_nloy_spend,by="WEEK_NUM")
organic_week_loy_spend
```
```{r plot_organic_week_loy_spend,echo=FALSE}
# plot Organic Weekly Agregate SPEND by LOYAL
library(latticeExtra)
# --> construct separate plots for each series
obj1 <- xyplot(SPEND_NLOY ~ WEEK_NUM, organic_week_loy_spend, main="Organic Weekly Agregate SPEND by LOYAL",type = "l" , lwd=2)
obj2 <- xyplot(SPEND_LOY ~ WEEK_NUM, organic_week_loy_spend, type = "l", lwd=2)
# --> Make the plot with second y axis AND legend:
doubleYScale(obj1, obj2, text = c("NON-LOYAL", "LOYAL") , add.ylab2 = TRUE)
```
```{r organic_week_spend,include=FALSE}
# merge weekly SPEND data
organic_week_spend <- merge(organic_week_reg_spend,organic_week_dep_spend)
organic_week_spend <- merge(organic_week_spend,organic_week_brand_spend)
organic_week_spend <- merge(organic_week_spend,organic_week_loy_spend)
organic_week_spend <- organic_week_spend%>%mutate(WEEK_NUM=as.factor(WEEK_NUM))
head(organic_week_spend)
str(organic_week_spend)
summary(organic_week_spend)
```
```{r scaling, include=FALSE}
# scaling data
organic_week_spend_s <- scale(organic_week_spend[2:11])
head(organic_week_spend_s)
```

## PCA Model
* Scaling the data and fit PCA to explore group pattern and possible dimension reduction.
* Frome Scree Plot, Pc1 explains 57.7% of variances and Pc2 explains 11.8% of variances. "Variables - PCA" plot shows "SPEND_NFOOD", "SPEND_C", "SPEND_NLOY" head to Pc1 significantly. Thus, reduced dimension which only contains those three variables is introduced for model selection.
* "Individulas - PCA" plot indicates the data might be clustered into 3-4 clusters.

```{r eigenvalues}
set.seed(7047)
# fit PCA
library(factoextra)
# Compute PCA
res.pca <- prcomp(organic_week_spend_s, scale = TRUE)
#Visualize eigenvalues (scree plot). Show the percentage of variances explained by each principal component.
fviz_eig(res.pca)
```
```{r indPCA}
#Graph of individuals. Individuals with a similar profile are grouped together.
fviz_pca_ind(res.pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```
```{r VarPlotPCA}
#Graph of variables. Positive correlated variables point to the same side of the plot. Negative correlated variables point to opposite sides of the graph.
fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```
```{r biplot,include=FALSE,echo=FALSE}
#Biplot of individuals and variables
fviz_pca_biplot(res.pca, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969"  # Individuals color
                )
```
```{r AccessPCA, include=FALSE}
#Access to the PCA results
library(factoextra)
# Eigenvalues
eig.val <- get_eigenvalue(res.pca)
eig.val
  
# Results for Variables
res.var <- get_pca_var(res.pca)
res.var$coord          # Coordinates
res.var$contrib        # Contributions to the PCs
res.var$cos2           # Quality of representation 
# Results for individuals
res.ind <- get_pca_ind(res.pca)
res.ind$coord          # Coordinates
res.ind$contrib        # Contributions to the PCs
res.ind$cos2           # Quality of representation 
```

## K-MEANS Model
* Euclidean Distance is used.
* Distance Plots indicates there might be three clusters. The dimension reduced data seems provide more clear clustering.
* K-MEANS Plots for different k shows possible over-fitting for models with k>4.
* Dimension Reduced Models reduced sum of square significantly.(See sum of square plot)
* Combining all plots and clusters selection criterion, k=3 and dimension reduced model is selected, because this model provide more clear clustering plots, lower sum of square and acceptable Average Silhouette Coefficient and Dunn Index.

```{r distanceplot}
library(factoextra)
organic_week_spend_s_c <- organic_week_spend_s[,c(4,5,10)]
distance <- get_dist(organic_week_spend_s)
distance_c <- get_dist(organic_week_spend_s_c)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))+ggtitle("Distance Plot (Full Dimension)")
fviz_dist(distance_c, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))+ggtitle("Distance Plot (Reduced Dimension)")
```
```{r fitkmeans, include=FALSE}
# fit kmeans models with different k
k2 <- kmeans(organic_week_spend_s, centers = 2, nstart = 25)
k3 <- kmeans(organic_week_spend_s, centers = 3, nstart = 25)
k4 <- kmeans(organic_week_spend_s, centers = 4, nstart = 25)
k5 <- kmeans(organic_week_spend_s, centers = 5, nstart = 25)
k6 <- kmeans(organic_week_spend_s, centers = 6, nstart = 25)
k7 <- kmeans(organic_week_spend_s, centers = 7, nstart = 25)

k2_c <- kmeans(organic_week_spend_s_c, centers = 2, nstart = 25)
k3_c <- kmeans(organic_week_spend_s_c, centers = 3, nstart = 25)
k4_c <- kmeans(organic_week_spend_s_c, centers = 4, nstart = 25)
k5_c <- kmeans(organic_week_spend_s_c, centers = 5, nstart = 25)
k6_c <- kmeans(organic_week_spend_s_c, centers = 6, nstart = 25)
k7_c <- kmeans(organic_week_spend_s_c, centers = 7, nstart = 25)


# # store plots to compare
library(factoextra)
p2 <- fviz_cluster(k2, geom = "point", data = organic_week_spend_s) + ggtitle("k = 2 (full)")
p3 <- fviz_cluster(k3, geom = "point", data = organic_week_spend_s) + ggtitle("k = 3(full)")
p4 <- fviz_cluster(k4, geom = "point", data = organic_week_spend_s) + ggtitle("k = 4(full)")
p5 <- fviz_cluster(k5, geom = "point", data = organic_week_spend_s) + ggtitle("k = 5(full)")
p6 <- fviz_cluster(k6, geom = "point", data = organic_week_spend_s) + ggtitle("k = 6(full)")
p7 <- fviz_cluster(k7, geom = "point", data = organic_week_spend_s) + ggtitle("k = 7(full)")


p2_c <- fviz_cluster(k2_c, geom = "point", data = organic_week_spend_s_c) + ggtitle("k = 2 (reduced)")
p3_c <- fviz_cluster(k3_c, geom = "point", data = organic_week_spend_s_c) + ggtitle("k = 3(reduced)")
p4_c <- fviz_cluster(k4_c, geom = "point", data = organic_week_spend_s_c) + ggtitle("k = 4(reduced)")
p5_c <- fviz_cluster(k5_c, geom = "point", data = organic_week_spend_s_c) + ggtitle("k = 5(reduced)")
p6_c <- fviz_cluster(k6_c, geom = "point", data = organic_week_spend_s_c) + ggtitle("k = 6(reduced)")
p7_c <- fviz_cluster(k7_c, geom = "point", data = organic_week_spend_s_c) + ggtitle("k = 7(reduced)")
```

```{r kmeanplot}
library(gridExtra)
grid.arrange(p2,p3,p4,p5,p6,p7, nrow = 3)
grid.arrange(p2_c,p3_c,p4_c,p5_c,p6_c,p7_c, nrow = 3)
```


```{r sum_of_square_compare}
# Determine number of clusters - simple within group sum of squares method is used.
wss <- (nrow(organic_week_spend_s)-1)*sum(apply(organic_week_spend_s,2,var))
for (i in 2:10) wss[i] <- sum(kmeans(organic_week_spend_s,
                                     centers=i)$withinss)
plot(1:10, wss, type="b", xlab="Number of Clusters",ylab="Within groups sum of squares",main ="sum of squares method (full)" )

wss_c <- (nrow(organic_week_spend_s_c)-1)*sum(apply(organic_week_spend_s_c,2,var))
for (i in 2:10) wss_c[i] <- sum(kmeans(organic_week_spend_s_c,
                                     centers=i)$withinss)
plot(1:10, wss_c, type="b", xlab="Number of Clusters",ylab="Within groups sum of squares",main ="sum of squares method(reduced)" )


```
```{r strength, include=FALSE}
# Determine number of clusters - Prediction strength for estimating number of clusters
library(fpc)
prediction.strength(organic_week_spend_s, Gmin=2, Gmax=7, M=5,cutoff=0.8)
prediction.strength(organic_week_spend_s_c, Gmin=2, Gmax=7, M=5,cutoff=0.8)
```
```{r Silhouette&dnn}
# fpc package has cluster.stat() function that can calcuate other cluster validity measures such as Average Silhouette Coefficient (between -1 and 1, the higher the better), or Dunn index (betwen 0 and infinity, the higher the better): 
d = dist(organic_week_spend_s, method = "euclidean")
result = matrix(nrow = 14, ncol = 3)
for (i in 2:10){
  cluster_result = kmeans(organic_week_spend_s, i)
  clusterstat=cluster.stats(d, cluster_result$cluster)
  result[i-1,1]=i
  result[i-1,2]=clusterstat$avg.silwidth
  result[i-1,3]=clusterstat$dunn   
}
plot(result[,c(1,2)], type="l", ylab = 'silhouette width', xlab = 'number of clusters',main = "Average Silhouette Coefficient (full)")
plot(result[,c(1,3)], type="l", ylab = 'dunn index', xlab = 'number of clusters',main = "Dunn index (full)")


d_c = dist(organic_week_spend_s_c, method = "euclidean")
result = matrix(nrow = 14, ncol = 3)
for (i in 2:10){
  cluster_result = kmeans(organic_week_spend_s_c, i)
  clusterstat=cluster.stats(d_c, cluster_result$cluster)
  result[i-1,1]=i
  result[i-1,2]=clusterstat$avg.silwidth
  result[i-1,3]=clusterstat$dunn   
}
plot(result[,c(1,2)], type="l", ylab = 'silhouette width', xlab = 'number of clusters',main = "Average Silhouette Coefficient (reduced)")
plot(result[,c(1,3)], type="l", ylab = 'dunn index', xlab = 'number of clusters',main = "Dunn index (reduced)")

```

## Hierarchical Clustering
* Hierarchical Clustering also show a clear group when using k=3 as cut-off and provide similary results as K-MEANS model does. So k=3 is validated as a good cluster for this data.
```{r Hierarchical}
#Wards Method or Hierarchical clustering
#Calculate the distance matrix
seed.dist=dist(organic_week_spend_s)
#Obtain clusters using the Wards method
seed.hclust=hclust(seed.dist, method="ward.D")
plot(seed.hclust,main = "Cluster Dendrogram (full)")
#Cut Dendrogram into 3 Clusters
rect.hclust(seed.hclust, k=3)


#Wards Method or Hierarchical clustering
#Calculate the distance matrix
seed.dist=dist(organic_week_spend_s_c)
#Obtain clusters using the Wards method
seed.hclust=hclust(seed.dist, method="ward.D")
plot(seed.hclust,main = "Cluster Dendrogram (reduced)")
#Cut Dendrogram into 3 Clusters
rect.hclust(seed.hclust, k=3)
```

## Session Conclusion
*Best weeks for marketing organic sell (week 53~104 converted back to 1~52 order for annual comparing):
  - 1st Quarter(Winter time): 1  2  3  4  5  8  9 10 11 13 
  - 2nd Quarter(Spring time): 14 15 17 18 20 24
  - 3rd Quarter: 34 38 
  - 4th Quarter(Holiday Season): 40 43 44 46 49 5
* Supprise: Summer and early fall does not seem good for Organic Selling
  - Possible Reason 1: many other produce and fruit source during Summer and and early Fall
  - Possible Reason 2: consumers have different purchasing behaviors during this seasons
```{r}
SPEND_KMEANS <- k3_c
SPEND_KMEANS
fviz_cluster(SPEND_KMEANS, data = organic_week_spend_s_c)+ggtitle("Organic Week Kmeans Final Model")
```
```{r include=FALSE}
CLUSTER <- data.frame(WEEK_NUM=as.integer(organic_week_spend$WEEK_NUM),
           CLUTSER_NUM=SPEND_KMEANS$cluster)

CLUSTER <- CLUSTER%>%mutate(WEEK_SUB=if_else(WEEK_NUM>52,52，0))%>%mutate(WEEK=WEEK_NUM-WEEK_SUB)%>%filter(CLUTSER_NUM==2)

unique(CLUSTER$WEEK) 
```